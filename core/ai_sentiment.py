"""
AI Sentiment Analysis - ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ñ
Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ” OpenAI Ğ´Ğ»Ñ Ğ³Ğ»Ğ¸Ğ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ ĞµĞ¼Ğ¾Ñ†Ñ–Ğ¹ Ñ‚Ğ° Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ñ– Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½ÑŒ
"""

import asyncio
import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
import logging
import os

logger = logging.getLogger(__name__)

@dataclass
class SentimentResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ñ"""
    text: str
    sentiment: str  # positive, negative, neutral, mixed
    confidence: float
    emotions: Dict[str, float] = field(default_factory=dict)
    toxicity_score: float = 0.0
    spam_probability: float = 0.0
    language: str = "uk"
    keywords: List[str] = field(default_factory=list)
    intent: str = ""
    summary: str = ""


class AISentimentAnalyzer:
    """AI-Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ñ"""
    
    EMOTION_KEYWORDS = {
        "positive": ["Ğ´ÑĞºÑƒÑ", "Ñ‡ÑƒĞ´Ğ¾Ğ²Ğ¾", "ÑÑƒĞ¿ĞµÑ€", "Ğ²Ñ–Ğ´Ğ¼Ñ–Ğ½Ğ½Ğ¾", "ĞºĞ»Ğ°ÑĞ½Ğ¾", "Ñ€Ğ°Ğ´Ğ¸Ğ¹", "Ñ‰Ğ°ÑĞ»Ğ¸Ğ²Ğ¸Ğ¹", "Ğ»ÑĞ±Ğ¾Ğ²", "Ğ½Ğ°Ğ¹ĞºÑ€Ğ°Ñ‰Ğ¸Ğ¹"],
        "negative": ["Ğ¿Ğ¾Ğ³Ğ°Ğ½Ğ¸Ğ¹", "Ğ¶Ğ°Ñ…Ğ»Ğ¸Ğ²Ğ¾", "Ñ€Ğ¾Ğ·Ñ‡Ğ°Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹", "Ğ·Ğ»Ğ¸Ğ¹", "Ğ½ĞµĞ½Ğ°Ğ²Ğ¸Ğ´Ğ¶Ñƒ", "Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°", "ÑĞºĞ°Ñ€Ğ³Ğ°", "Ğ¾Ğ±Ğ¼Ğ°Ğ½"],
        "neutral": ["Ğ´Ğ¾Ğ±Ñ€Ğµ", "Ğ¾Ğº", "Ğ·Ñ€Ğ¾Ğ·ÑƒĞ¼Ñ–Ğ²", "Ñ‚Ğ°Ğº", "Ğ½Ñ–", "Ğ¼Ğ¾Ğ¶Ğ»Ğ¸Ğ²Ğ¾", "Ğ±ÑƒĞ´Ğµ"],
        "urgent": ["Ñ‚ĞµÑ€Ğ¼Ñ–Ğ½Ğ¾Ğ²Ğ¾", "ÑˆĞ²Ğ¸Ğ´ĞºĞ¾", "Ğ½ĞµĞ³Ğ°Ğ¹Ğ½Ğ¾", "ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾", "Ğ²Ğ°Ğ¶Ğ»Ğ¸Ğ²Ğ¾", "Ñ‚ĞµÑ€Ğ¼Ñ–Ğ½"],
        "question": ["ÑĞº", "Ñ‡Ğ¾Ğ¼Ñƒ", "ĞºĞ¾Ğ»Ğ¸", "Ğ´Ğµ", "Ñ…Ñ‚Ğ¾", "Ñ‰Ğ¾", "ÑĞºÑ–Ğ»ÑŒĞºĞ¸", "?"]
    }
    
    TOXIC_PATTERNS = [
        r'\b(Ñ–Ğ´Ñ–Ğ¾Ñ‚|Ğ´ÑƒÑ€ĞµĞ½ÑŒ|Ğ¿Ñ€Ğ¸Ğ´ÑƒÑ€Ğ¾Ğº|Ğ»Ğ¾Ñ…|ÑƒÑ€Ğ¾Ğ´)\b',
        r'\b(Ğ¾Ğ±Ğ¼Ğ°Ğ½|ÑˆĞ°Ñ…Ñ€Ğ°Ğ¹|ĞºĞ¸Ğ´Ğ°Ğ»Ğ¾Ğ²Ğ¾|Ñ€Ğ¾Ğ·Ğ²Ğ¾Ğ´)\b',
        r'[Ğ-Ğ¯Ğ†Ğ‡Ğ„]{5,}',  # ĞšĞ°Ğ¿Ñ
    ]
    
    def __init__(self):
        self.analysis_cache: Dict[str, SentimentResult] = {}
        self.stats = {
            "total_analyzed": 0,
            "by_sentiment": {"positive": 0, "negative": 0, "neutral": 0, "mixed": 0},
            "avg_toxicity": 0.0,
            "total_toxicity": 0.0
        }
        self._openai_client = None
    
    def _get_openai_client(self):
        """Ğ†Ğ½Ñ–Ñ†Ñ–Ğ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ OpenAI ĞºĞ»Ñ–Ñ”Ğ½Ñ‚Ğ°"""
        if self._openai_client is None:
            try:
                from openai import OpenAI
                api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("AI_INTEGRATIONS_OPENAI_API_KEY")
                if api_key:
                    self._openai_client = OpenAI(api_key=api_key)
            except Exception as e:
                logger.warning(f"OpenAI not available: {e}")
        return self._openai_client
    
    async def analyze_sentiment(self, text: str, use_ai: bool = True) -> SentimentResult:
        """ĞĞ½Ğ°Ğ»Ñ–Ğ· Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ñ Ñ‚ĞµĞºÑÑ‚Ñƒ"""
        if not text or not text.strip():
            return SentimentResult(
                text="",
                sentiment="neutral",
                confidence=0.0
            )
        
        cache_key = hash(text[:100])
        if cache_key in self.analysis_cache:
            return self.analysis_cache[cache_key]
        
        basic_result = self._basic_analysis(text)
        
        if use_ai and self._get_openai_client():
            try:
                ai_result = await self._ai_analysis(text, basic_result)
                result = ai_result
            except Exception as e:
                logger.warning(f"AI analysis failed: {e}")
                result = basic_result
        else:
            result = basic_result
        
        self.analysis_cache[cache_key] = result
        self._update_stats(result)
        
        return result
    
    def _basic_analysis(self, text: str) -> SentimentResult:
        """Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– ĞºĞ»ÑÑ‡Ğ¾Ğ²Ğ¸Ñ… ÑĞ»Ñ–Ğ²"""
        text_lower = text.lower()
        
        scores = {"positive": 0, "negative": 0, "neutral": 0}
        keywords_found = []
        
        for sentiment, words in self.EMOTION_KEYWORDS.items():
            if sentiment in ["urgent", "question"]:
                continue
            for word in words:
                if word in text_lower:
                    scores[sentiment] += 1
                    keywords_found.append(word)
        
        toxicity = self._calculate_toxicity(text)
        spam_prob = self._calculate_spam_probability(text)
        
        total = sum(scores.values())
        if total == 0:
            sentiment = "neutral"
            confidence = 0.5
        else:
            sentiment = max(scores, key=scores.get)
            confidence = scores[sentiment] / total
        
        emotions = {
            "joy": scores["positive"] / max(total, 1),
            "anger": min(toxicity, 1.0),
            "sadness": scores["negative"] / max(total, 1) * 0.5,
            "fear": 0.0,
            "surprise": 0.0
        }
        
        intent = "question" if "?" in text or any(w in text_lower for w in self.EMOTION_KEYWORDS["question"]) else "statement"
        if any(w in text_lower for w in self.EMOTION_KEYWORDS["urgent"]):
            intent = "urgent_request"
        
        return SentimentResult(
            text=text[:200],
            sentiment=sentiment,
            confidence=round(confidence, 2),
            emotions=emotions,
            toxicity_score=round(toxicity, 2),
            spam_probability=round(spam_prob, 2),
            language="uk",
            keywords=keywords_found[:10],
            intent=intent,
            summary=f"{'ĞŸĞ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¹' if sentiment == 'positive' else 'ĞĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¹' if sentiment == 'negative' else 'ĞĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹'} Ğ½Ğ°ÑÑ‚Ñ€Ñ–Ğ¹"
        )
    
    async def _ai_analysis(self, text: str, basic: SentimentResult) -> SentimentResult:
        """AI Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ñ‡ĞµÑ€ĞµĞ· OpenAI"""
        client = self._get_openai_client()
        if not client:
            return basic
        
        prompt = f"""ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·ÑƒĞ¹ Ğ½Ğ°ÑÑ‚Ñ€Ñ–Ğ¹ Ñ†ÑŒĞ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ Ğ¼Ğ¾Ğ²Ğ¾Ñ.
Ğ¢ĞµĞºÑÑ‚: "{text[:500]}"

Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ñƒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ– JSON:
{{
    "sentiment": "positive/negative/neutral/mixed",
    "confidence": 0.0-1.0,
    "emotions": {{"joy": 0.0-1.0, "anger": 0.0-1.0, "sadness": 0.0-1.0}},
    "intent": "question/statement/request/complaint",
    "summary": "ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ğ¿Ğ¸Ñ"
}}"""
        
        try:
            response = await asyncio.to_thread(
                lambda: client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=200,
                    temperature=0.3
                )
            )
            
            content = response.choices[0].message.content
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                
                return SentimentResult(
                    text=text[:200],
                    sentiment=data.get("sentiment", basic.sentiment),
                    confidence=float(data.get("confidence", basic.confidence)),
                    emotions=data.get("emotions", basic.emotions),
                    toxicity_score=basic.toxicity_score,
                    spam_probability=basic.spam_probability,
                    language="uk",
                    keywords=basic.keywords,
                    intent=data.get("intent", basic.intent),
                    summary=data.get("summary", basic.summary)
                )
        except Exception as e:
            logger.warning(f"AI parsing error: {e}")
        
        return basic
    
    def _calculate_toxicity(self, text: str) -> float:
        """Ğ Ğ¾Ğ·Ñ€Ğ°Ñ…ÑƒĞ½Ğ¾Ğº Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ñ–"""
        score = 0.0
        
        for pattern in self.TOXIC_PATTERNS:
            matches = re.findall(pattern, text, re.IGNORECASE)
            score += len(matches) * 0.3
        
        caps_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)
        if caps_ratio > 0.5:
            score += 0.2
        
        if text.count('!') > 3:
            score += 0.1
        
        return min(score, 1.0)
    
    def _calculate_spam_probability(self, text: str) -> float:
        """Ğ Ğ¾Ğ·Ñ€Ğ°Ñ…ÑƒĞ½Ğ¾Ğº Ğ¹Ğ¼Ğ¾Ğ²Ñ–Ñ€Ğ½Ğ¾ÑÑ‚Ñ– ÑĞ¿Ğ°Ğ¼Ñƒ"""
        score = 0.0
        
        if re.search(r'https?://', text):
            score += 0.2
        
        if re.search(r'@\w+', text):
            score += 0.1
        
        spam_words = ["Ğ±ĞµĞ·ĞºĞ¾ÑˆÑ‚Ğ¾Ğ²Ğ½Ğ¾", "Ğ²Ğ¸Ğ³Ñ€Ğ°Ñˆ", "Ğ¿Ñ€Ğ¸Ğ·", "Ğ°ĞºÑ†Ñ–Ñ", "Ğ·Ğ½Ğ¸Ğ¶ĞºĞ°", "Ñ‚ĞµÑ€Ğ¼Ñ–Ğ½Ğ¾Ğ²"]
        for word in spam_words:
            if word in text.lower():
                score += 0.15
        
        emoji_count = len(re.findall(r'[\U0001F600-\U0001F64F]', text))
        if emoji_count > 5:
            score += 0.1
        
        return min(score, 1.0)
    
    async def analyze_batch(self, texts: List[str]) -> List[SentimentResult]:
        """ĞŸĞ°ĞºĞµÑ‚Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·"""
        results = []
        for text in texts:
            result = await self.analyze_sentiment(text, use_ai=False)
            results.append(result)
        return results
    
    def _update_stats(self, result: SentimentResult):
        """ĞĞ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸"""
        self.stats["total_analyzed"] += 1
        self.stats["by_sentiment"][result.sentiment] = self.stats["by_sentiment"].get(result.sentiment, 0) + 1
        self.stats["total_toxicity"] += result.toxicity_score
        self.stats["avg_toxicity"] = self.stats["total_toxicity"] / self.stats["total_analyzed"]
    
    def get_stats(self) -> Dict:
        """ĞÑ‚Ñ€Ğ¸Ğ¼Ğ°Ğ½Ğ½Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸"""
        return self.stats
    
    def format_result(self, result: SentimentResult) -> str:
        """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñƒ"""
        sentiment_icons = {
            "positive": "ğŸ˜Š",
            "negative": "ğŸ˜",
            "neutral": "ğŸ˜",
            "mixed": "ğŸ¤”"
        }
        
        intent_icons = {
            "question": "â“",
            "statement": "ğŸ’¬",
            "request": "ğŸ“©",
            "complaint": "âš ï¸",
            "urgent_request": "ğŸš¨"
        }
        
        text = f"""<b>ğŸ§  ĞĞĞĞ›Ğ†Ğ— ĞĞĞ¡Ğ¢Ğ ĞĞ®</b>

<b>ğŸ“ Ğ¢ĞµĞºÑÑ‚:</b> <i>{result.text[:100]}...</i>

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

<b>ğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢:</b>
â”œ {sentiment_icons.get(result.sentiment, 'â“')} ĞĞ°ÑÑ‚Ñ€Ñ–Ğ¹: <b>{result.sentiment.upper()}</b>
â”œ ğŸ“ˆ Ğ’Ğ¿ĞµĞ²Ğ½ĞµĞ½Ñ–ÑÑ‚ÑŒ: <b>{result.confidence * 100:.0f}%</b>
â”œ â˜£ï¸ Ğ¢Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ–ÑÑ‚ÑŒ: <b>{result.toxicity_score * 100:.0f}%</b>
â”œ ğŸ“§ Ğ¡Ğ¿Ğ°Ğ¼: <b>{result.spam_probability * 100:.0f}%</b>
â”” {intent_icons.get(result.intent, 'ğŸ’¬')} Ğ†Ğ½Ñ‚ĞµĞ½Ñ‚: <b>{result.intent}</b>

<b>ğŸ’­ Ğ•ĞœĞĞ¦Ğ†Ğ‡:</b>"""
        
        for emotion, score in result.emotions.items():
            bar = "â–ˆ" * int(score * 10) + "â–‘" * (10 - int(score * 10))
            text += f"\nâ”œ {emotion}: {bar} {score * 100:.0f}%"
        
        text += f"\n\n<b>ğŸ“Œ Ğ ĞµĞ·ÑĞ¼Ğµ:</b> {result.summary}"
        
        return text
    
    def format_stats_report(self) -> str:
        """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ·Ğ²Ñ–Ñ‚Ñƒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸"""
        stats = self.get_stats()
        
        text = f"""<b>ğŸ§  AI SENTIMENT ANALYZER</b>
<i>Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ñ—Ğ²</i>

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

<b>ğŸ“Š Ğ—ĞĞ“ĞĞ›Ğ¬ĞĞ Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ:</b>
â”œ ğŸ“ ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: <b>{stats['total_analyzed']}</b>
â”” â˜£ï¸ Ğ¡ĞµÑ€. Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ–ÑÑ‚ÑŒ: <b>{stats['avg_toxicity'] * 100:.1f}%</b>

<b>ğŸ“ˆ ĞŸĞ ĞĞĞ¡Ğ¢Ğ ĞĞ¯Ğ¥:</b>"""
        
        for sentiment, count in stats["by_sentiment"].items():
            icon = {"positive": "ğŸ˜Š", "negative": "ğŸ˜", "neutral": "ğŸ˜", "mixed": "ğŸ¤”"}.get(sentiment, "â“")
            text += f"\nâ”œ {icon} {sentiment}: <b>{count}</b>"
        
        return text


ai_sentiment = AISentimentAnalyzer()
