"""
X-Ray Metadata - ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ğ³Ğ»Ğ¸Ğ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ…
Ğ’Ğ¸Ñ‚ÑĞ³ÑƒÑ” Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ²Ğ°Ğ½Ñƒ Ñ–Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ñ–Ñ Ğ· Ñ„Ğ°Ğ¹Ğ»Ñ–Ğ² Ñ‚Ğ° Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½ÑŒ
"""

import asyncio
import hashlib
import json
import re
import struct
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
import logging

logger = logging.getLogger(__name__)

@dataclass
class XRayResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ X-Ray Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ"""
    file_id: str
    file_type: str
    file_size: int
    analysis_time: datetime
    basic_metadata: Dict = field(default_factory=dict)
    hidden_data: Dict = field(default_factory=dict)
    geolocation: Optional[Dict] = None
    device_info: Optional[Dict] = None
    timestamps: Dict = field(default_factory=dict)
    signatures: List[str] = field(default_factory=list)
    anomalies: List[str] = field(default_factory=list)
    risk_score: float = 0.0


class XRayMetadata:
    """Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° X-Ray Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ…"""
    
    FILE_SIGNATURES = {
        b'\xff\xd8\xff\xe0': ('JPEG', 'image'),
        b'\xff\xd8\xff\xe1': ('JPEG/EXIF', 'image'),
        b'\x89PNG\r\n\x1a\n': ('PNG', 'image'),
        b'GIF87a': ('GIF87', 'image'),
        b'GIF89a': ('GIF89', 'image'),
        b'%PDF-': ('PDF', 'document'),
        b'PK\x03\x04': ('ZIP/DOCX', 'archive'),
        b'Rar!\x1a\x07': ('RAR', 'archive'),
        b'\x00\x00\x00\x1c': ('MP4/MOV', 'video'),
        b'\x00\x00\x00\x20': ('MP4', 'video'),
        b'\x1a\x45\xdf\xa3': ('WebM/MKV', 'video'),
        b'OggS': ('OGG', 'audio'),
        b'ID3': ('MP3', 'audio'),
        b'\xff\xfb': ('MP3', 'audio'),
        b'fLaC': ('FLAC', 'audio'),
        b'RIFF': ('WAV/AVI', 'media'),
    }
    
    EXIF_TAGS = {
        0x010F: 'Make',
        0x0110: 'Model',
        0x0112: 'Orientation',
        0x011A: 'XResolution',
        0x011B: 'YResolution',
        0x0132: 'DateTime',
        0x8769: 'ExifOffset',
        0x8825: 'GPSInfo',
        0xA002: 'ExifImageWidth',
        0xA003: 'ExifImageHeight',
        0x9003: 'DateTimeOriginal',
        0x9004: 'DateTimeDigitized',
    }
    
    def __init__(self, storage_path: str = "data/xray_results"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        self.analysis_cache: Dict[str, XRayResult] = {}
        self.stats = {
            "total_analyzed": 0,
            "by_type": {},
            "anomalies_found": 0,
            "geo_extracted": 0
        }
    
    async def analyze(self, file_data: bytes, file_info: Dict = None) -> XRayResult:
        """ĞŸĞ¾Ğ²Ğ½Ğ¸Ğ¹ X-Ray Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ñ„Ğ°Ğ¹Ğ»Ñƒ"""
        file_info = file_info or {}
        file_id = file_info.get('file_id', hashlib.md5(file_data[:1000]).hexdigest())
        
        if file_id in self.analysis_cache:
            return self.analysis_cache[file_id]
        
        file_type, category = self._detect_file_type(file_data)
        
        result = XRayResult(
            file_id=file_id,
            file_type=file_type,
            file_size=len(file_data),
            analysis_time=datetime.now()
        )
        
        result.basic_metadata = self._extract_basic_metadata(file_data, file_info)
        result.signatures = self._extract_signatures(file_data)
        result.timestamps = self._extract_timestamps(file_data)
        
        if category == 'image':
            exif_data = self._extract_exif(file_data)
            result.basic_metadata.update(exif_data)
            
            if 'gps' in exif_data:
                result.geolocation = exif_data['gps']
                self.stats["geo_extracted"] += 1
            
            if 'device' in exif_data:
                result.device_info = exif_data['device']
        
        result.hidden_data = self._search_hidden_data(file_data)
        
        result.anomalies = self._detect_anomalies(file_data, result)
        result.risk_score = self._calculate_risk_score(result)
        
        if result.anomalies:
            self.stats["anomalies_found"] += len(result.anomalies)
        
        self.analysis_cache[file_id] = result
        
        self.stats["total_analyzed"] += 1
        self.stats["by_type"][file_type] = self.stats["by_type"].get(file_type, 0) + 1
        
        await self._save_result(result)
        
        return result
    
    def _detect_file_type(self, data: bytes) -> Tuple[str, str]:
        """Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ñ‚Ğ¸Ğ¿Ñƒ Ñ„Ğ°Ğ¹Ğ»Ñƒ Ğ·Ğ° ÑĞ¸Ğ³Ğ½Ğ°Ñ‚ÑƒÑ€Ğ¾Ñ"""
        for sig, (file_type, category) in self.FILE_SIGNATURES.items():
            if data.startswith(sig):
                return file_type, category
        
        return 'UNKNOWN', 'unknown'
    
    def _extract_basic_metadata(self, data: bytes, file_info: Dict) -> Dict:
        """Ğ’Ğ¸Ñ‚ÑĞ³Ğ½ĞµĞ½Ğ½Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¸Ñ… Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ…"""
        return {
            "size_bytes": len(data),
            "size_kb": round(len(data) / 1024, 2),
            "hash_md5": hashlib.md5(data).hexdigest(),
            "hash_sha256": hashlib.sha256(data).hexdigest()[:32],
            "magic_bytes": data[:16].hex(),
            "entropy": self._calculate_entropy(data),
            "null_bytes_ratio": data.count(b'\x00') / max(len(data), 1),
            "printable_ratio": sum(1 for b in data if 32 <= b <= 126) / max(len(data), 1),
            **file_info
        }
    
    def _calculate_entropy(self, data: bytes) -> float:
        """Ğ Ğ¾Ğ·Ñ€Ğ°Ñ…ÑƒĞ½Ğ¾Ğº ĞµĞ½Ñ‚Ñ€Ğ¾Ğ¿Ñ–Ñ—"""
        import math
        if not data:
            return 0.0
        
        freq = {}
        for byte in data:
            freq[byte] = freq.get(byte, 0) + 1
        
        entropy = 0.0
        for count in freq.values():
            p = count / len(data)
            if p > 0:
                entropy -= p * math.log2(p)
        
        return round(entropy, 4)
    
    def _extract_signatures(self, data: bytes) -> List[str]:
        """Ğ’Ğ¸Ñ‚ÑĞ³Ğ½ĞµĞ½Ğ½Ñ Ğ²ÑÑ–Ñ… Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¸Ñ… ÑĞ¸Ğ³Ğ½Ğ°Ñ‚ÑƒÑ€"""
        signatures = []
        
        for sig, (file_type, _) in self.FILE_SIGNATURES.items():
            pos = data.find(sig)
            if pos != -1:
                signatures.append(f"{file_type}@{pos}")
        
        patterns = [
            (b'Photoshop', 'Adobe_Photoshop'),
            (b'GIMP', 'GIMP'),
            (b'Adobe', 'Adobe_Product'),
            (b'Canon', 'Canon_Camera'),
            (b'NIKON', 'Nikon_Camera'),
            (b'Apple', 'Apple_Device'),
            (b'Samsung', 'Samsung_Device'),
            (b'DCIM', 'Camera_Image'),
        ]
        
        for pattern, name in patterns:
            if pattern in data:
                signatures.append(name)
        
        return signatures
    
    def _extract_timestamps(self, data: bytes) -> Dict:
        """Ğ’Ğ¸Ñ‚ÑĞ³Ğ½ĞµĞ½Ğ½Ñ Ñ‡Ğ°ÑĞ¾Ğ²Ğ¸Ñ… Ğ¼Ñ–Ñ‚Ğ¾Ğº"""
        timestamps = {}
        
        datetime_pattern = rb'\d{4}:\d{2}:\d{2} \d{2}:\d{2}:\d{2}'
        matches = re.findall(datetime_pattern, data)
        
        for i, match in enumerate(matches[:5]):
            try:
                dt_str = match.decode('ascii')
                timestamps[f"timestamp_{i}"] = dt_str
            except:
                pass
        
        return timestamps
    
    def _extract_exif(self, data: bytes) -> Dict:
        """Ğ’Ğ¸Ñ‚ÑĞ³Ğ½ĞµĞ½Ğ½Ñ EXIF Ğ´Ğ°Ğ½Ğ¸Ñ…"""
        exif = {}
        
        try:
            exif_start = data.find(b'Exif\x00\x00')
            if exif_start == -1:
                return exif
            
            for pattern, name in [
                (b'Make', 'make'),
                (b'Model', 'model'),
                (b'DateTime', 'datetime'),
                (b'Software', 'software'),
            ]:
                pos = data.find(pattern, exif_start)
                if pos != -1:
                    value_start = pos + len(pattern) + 1
                    value_end = data.find(b'\x00', value_start)
                    if value_end != -1 and value_end - value_start < 100:
                        try:
                            value = data[value_start:value_end].decode('ascii', errors='ignore').strip()
                            if value:
                                exif[name] = value
                        except:
                            pass
            
            gps_pos = data.find(b'GPS')
            if gps_pos != -1:
                exif['gps'] = {'found': True, 'position': gps_pos}
            
            if exif.get('make') or exif.get('model'):
                exif['device'] = {
                    'make': exif.get('make', ''),
                    'model': exif.get('model', '')
                }
        
        except Exception as e:
            logger.warning(f"EXIF extraction error: {e}")
        
        return exif
    
    def _search_hidden_data(self, data: bytes) -> Dict:
        """ĞŸĞ¾ÑˆÑƒĞº Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…"""
        hidden = {}
        
        strings = []
        current = []
        for byte in data:
            if 32 <= byte <= 126:
                current.append(chr(byte))
            else:
                if len(current) >= 8:
                    strings.append(''.join(current))
                current = []
        
        interesting = [s for s in strings if any(kw in s.lower() for kw in 
            ['http', 'www', '@', 'password', 'secret', 'key', 'token', 'api'])]
        
        if interesting:
            hidden['suspicious_strings'] = interesting[:10]
        
        urls = re.findall(rb'https?://[^\s\x00]+', data)
        if urls:
            hidden['embedded_urls'] = [u.decode('ascii', errors='ignore') for u in urls[:5]]
        
        emails = re.findall(rb'[\w\.-]+@[\w\.-]+\.\w+', data)
        if emails:
            hidden['embedded_emails'] = [e.decode('ascii', errors='ignore') for e in emails[:5]]
        
        return hidden
    
    def _detect_anomalies(self, data: bytes, result: XRayResult) -> List[str]:
        """Ğ’Ğ¸ÑĞ²Ğ»ĞµĞ½Ğ½Ñ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ñ–Ğ¹"""
        anomalies = []
        
        entropy = result.basic_metadata.get('entropy', 0)
        if entropy > 7.9:
            anomalies.append("HIGH_ENTROPY: ĞœĞ¾Ğ¶Ğ»Ğ¸Ğ²Ğµ ÑˆĞ¸Ñ„Ñ€ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ°Ğ±Ğ¾ ÑÑ‚Ğ¸ÑĞ½ĞµĞ½Ğ½Ñ")
        elif entropy < 1.0 and len(data) > 1000:
            anomalies.append("LOW_ENTROPY: ĞŸÑ–Ğ´Ğ¾Ğ·Ñ€Ñ–Ğ»Ğ° Ğ¾Ğ´Ğ½Ğ¾Ñ€Ñ–Ğ´Ğ½Ñ–ÑÑ‚ÑŒ Ğ´Ğ°Ğ½Ğ¸Ñ…")
        
        if len(result.signatures) > 3:
            anomalies.append("MULTI_SIGNATURE: Ğ’Ğ¸ÑĞ²Ğ»ĞµĞ½Ğ¾ Ğ´ĞµĞºÑ–Ğ»ÑŒĞºĞ° Ñ‚Ğ¸Ğ¿Ñ–Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ–Ğ²")
        
        if result.hidden_data.get('embedded_urls'):
            anomalies.append("HIDDEN_URLS: Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ²Ğ±ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ñ– URL")
        
        if result.hidden_data.get('suspicious_strings'):
            anomalies.append("SUSPICIOUS_STRINGS: Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿Ñ–Ğ´Ğ¾Ğ·Ñ€Ñ–Ğ»Ñ– Ñ€ÑĞ´ĞºĞ¸")
        
        null_ratio = result.basic_metadata.get('null_bytes_ratio', 0)
        if null_ratio > 0.5:
            anomalies.append("HIGH_NULL_BYTES: ĞœĞ¾Ğ¶Ğ»Ğ¸Ğ²Ğ¸Ğ¹ padding Ğ°Ğ±Ğ¾ ÑÑ‚ĞµĞ³Ğ°Ğ½Ğ¾Ğ³Ñ€Ğ°Ñ„Ñ–Ñ")
        
        return anomalies
    
    def _calculate_risk_score(self, result: XRayResult) -> float:
        """Ğ Ğ¾Ğ·Ñ€Ğ°Ñ…ÑƒĞ½Ğ¾Ğº Ñ€Ñ–Ğ²Ğ½Ñ Ñ€Ğ¸Ğ·Ğ¸ĞºÑƒ"""
        score = 0.0
        
        score += len(result.anomalies) * 0.15
        
        if result.hidden_data.get('embedded_urls'):
            score += 0.2
        
        if result.hidden_data.get('suspicious_strings'):
            score += 0.15
        
        entropy = result.basic_metadata.get('entropy', 0)
        if entropy > 7.5:
            score += 0.1
        
        return min(round(score, 2), 1.0)
    
    async def _save_result(self, result: XRayResult):
        """Ğ—Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ½Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñƒ"""
        file_path = self.storage_path / f"{result.file_id[:16]}.json"
        
        data = {
            "file_id": result.file_id,
            "file_type": result.file_type,
            "file_size": result.file_size,
            "analysis_time": result.analysis_time.isoformat(),
            "basic_metadata": result.basic_metadata,
            "hidden_data": result.hidden_data,
            "geolocation": result.geolocation,
            "device_info": result.device_info,
            "timestamps": result.timestamps,
            "signatures": result.signatures,
            "anomalies": result.anomalies,
            "risk_score": result.risk_score
        }
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"Save error: {e}")
    
    def get_stats(self) -> Dict:
        """ĞÑ‚Ñ€Ğ¸Ğ¼Ğ°Ğ½Ğ½Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸"""
        return {
            **self.stats,
            "cache_size": len(self.analysis_cache)
        }
    
    def format_result(self, result: XRayResult) -> str:
        """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñƒ"""
        risk_bar = "â–ˆ" * int(result.risk_score * 10) + "â–‘" * (10 - int(result.risk_score * 10))
        risk_level = "ğŸŸ¢ LOW" if result.risk_score < 0.3 else "ğŸŸ¡ MEDIUM" if result.risk_score < 0.6 else "ğŸ”´ HIGH"
        
        text = f"""<b>ğŸ”¬ X-RAY METADATA ANALYSIS</b>

<b>ğŸ“ Ğ¤Ğ°Ğ¹Ğ»:</b> <code>{result.file_id[:16]}...</code>
<b>ğŸ“‚ Ğ¢Ğ¸Ğ¿:</b> {result.file_type}
<b>ğŸ“Š Ğ Ğ¾Ğ·Ğ¼Ñ–Ñ€:</b> {result.basic_metadata.get('size_kb', 0)} KB

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

<b>âš ï¸ Ğ Ğ˜Ğ—Ğ˜Ğš:</b> {risk_bar} {result.risk_score * 100:.0f}%
<b>Ğ Ñ–Ğ²ĞµĞ½ÑŒ:</b> {risk_level}

<b>ğŸ“‹ Ğ¡Ğ˜Ğ“ĞĞĞ¢Ğ£Ğ Ğ˜:</b>"""
        
        for sig in result.signatures[:5]:
            text += f"\nâ”œ {sig}"
        
        if not result.signatures:
            text += "\nâ”œ <i>ĞĞµ Ğ²Ğ¸ÑĞ²Ğ»ĞµĞ½Ğ¾</i>"
        
        text += "\n\n<b>ğŸ” ĞœĞ•Ğ¢ĞĞ”ĞĞĞ†:</b>"
        text += f"\nâ”œ Ğ•Ğ½Ñ‚Ñ€Ğ¾Ğ¿Ñ–Ñ: {result.basic_metadata.get('entropy', 0)}"
        text += f"\nâ”œ MD5: <code>{result.basic_metadata.get('hash_md5', '')[:16]}...</code>"
        
        if result.device_info:
            text += f"\n\n<b>ğŸ“± ĞŸĞ Ğ˜Ğ¡Ğ¢Ğ Ğ†Ğ™:</b>"
            text += f"\nâ”œ {result.device_info.get('make', '')} {result.device_info.get('model', '')}"
        
        if result.geolocation:
            text += f"\n\n<b>ğŸ“ Ğ“Ğ•ĞĞ›ĞĞšĞĞ¦Ğ†Ğ¯:</b> Ğ—Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾"
        
        if result.anomalies:
            text += f"\n\n<b>âš ï¸ ĞĞĞĞœĞĞ›Ğ†Ğ‡ ({len(result.anomalies)}):</b>"
            for anomaly in result.anomalies[:3]:
                text += f"\nâ”œ {anomaly}"
        
        if result.hidden_data.get('embedded_urls'):
            text += f"\n\n<b>ğŸ”— Ğ’Ğ‘Ğ£Ğ”ĞĞ’ĞĞĞ† URL:</b>"
            for url in result.hidden_data['embedded_urls'][:3]:
                text += f"\nâ”œ {url[:50]}..."
        
        return text
    
    def format_stats_report(self) -> str:
        """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ·Ğ²Ñ–Ñ‚Ñƒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸"""
        stats = self.get_stats()
        
        text = f"""<b>ğŸ”¬ X-RAY METADATA</b>
<i>Ğ“Ğ»Ğ¸Ğ±Ğ¾ĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ…</i>

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

<b>ğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ:</b>
â”œ ğŸ” ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: <b>{stats['total_analyzed']}</b>
â”œ âš ï¸ ĞĞ½Ğ¾Ğ¼Ğ°Ğ»Ñ–Ğ¹: <b>{stats['anomalies_found']}</b>
â”œ ğŸ“ Ğ“ĞµĞ¾Ğ»Ğ¾ĞºĞ°Ñ†Ñ–Ğ¹: <b>{stats['geo_extracted']}</b>
â”” ğŸ’¾ Ğ’ ĞºĞµÑˆÑ–: <b>{stats['cache_size']}</b>

<b>ğŸ“ ĞŸĞ Ğ¢Ğ˜ĞŸĞĞ¥:</b>"""
        
        for file_type, count in stats.get("by_type", {}).items():
            text += f"\nâ”œ {file_type}: <b>{count}</b>"
        
        if not stats.get("by_type"):
            text += "\n<i>ĞĞµĞ¼Ğ°Ñ” Ğ´Ğ°Ğ½Ğ¸Ñ…</i>"
        
        return text


xray_metadata = XRayMetadata()
